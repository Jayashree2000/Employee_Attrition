{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2ca7585",
   "metadata": {},
   "source": [
    "**Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46fe896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b31746",
   "metadata": {},
   "outputs": [],
   "source": [
    "empdata=pd.read_csv(r\"G:\\Guvi-Datascience\\Project\\Employee Attrition_Project 3\\Employee-Attrition - Employee-Attrition.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c81a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "empdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6789d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "empdata.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e1ac29",
   "metadata": {},
   "outputs": [],
   "source": [
    "empdata.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6340181",
   "metadata": {},
   "outputs": [],
   "source": [
    "empdata.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c28fe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop useless constant columns\n",
    "remove_cols = ['EmployeeCount', 'StandardHours', 'Over18','EmployeeNumber']\n",
    "empdata.drop(columns=remove_cols, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add179fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "empdata.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc82183e",
   "metadata": {},
   "source": [
    "**EDA**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b54aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbe492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separate Numerical & Categorical Columns\n",
    "# Numerical columns: int or float\n",
    "num_cols = [col for col in empdata.columns if empdata[col].nunique() >= 10]\n",
    "\n",
    "# Categorical columns: object type\n",
    "cat_cols = [col for col in empdata.columns if empdata[col].nunique() < 10]\n",
    "\n",
    "\n",
    "print(\"\\nNumerical Columns:\\n\", num_cols)\n",
    "print(\"\\nCategorical Columns:\\n\", cat_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a0971",
   "metadata": {},
   "source": [
    "**Univariate Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f2b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# UNIVARIATE ANALYSIS\n",
    "# Target Variable: Attrition\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=empdata, x='Attrition')\n",
    "plt.title(\"Attrition Count (0 = Stayed, 1 = Left)\")\n",
    "plt.xlabel(\"Attrition\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Percentage distribution of Attrition\n",
    "print(\"\\nAttrition Value Counts (%):\")\n",
    "print(empdata['Attrition'].value_counts(normalize=True) * 100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d4b58e",
   "metadata": {},
   "source": [
    "The attrition variable is highly imbalanced, with significantly fewer employees leaving than staying, which necessitates the use of resampling techniques like SMOTE and evaluation metrics such as Recall and ROC-AUC instead of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f26ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIVARIATE ANALYSIS - Numerical (Hist + Boxplot + Stats)\n",
    "\n",
    "# List of numerical columns\n",
    "num_cols_for_hist = [col for col in num_cols]\n",
    "\n",
    "for col in num_cols_for_hist:\n",
    "    \n",
    "    # ---- Statistics ----\n",
    "    mean_val = empdata[col].mean()\n",
    "    median_val = empdata[col].median()\n",
    "    percent_diff = abs(mean_val - median_val) / mean_val * 100\n",
    "\n",
    "    print(\"Column:\", col)\n",
    "    print(\"====================\")\n",
    "    print(\"Mean:\", round(mean_val, 2), \n",
    "          \" | Median:\", round(median_val, 2))\n",
    "    print(\"Mean-Median Difference:\", round(percent_diff, 2), \"%\")\n",
    "    print(\"Skewness:\", round(empdata[col].skew(), 2))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # ---- Plots SIDE BY SIDE ----\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # 1️⃣ Histogram + KDE\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(empdata[col], kde=True)\n",
    "    plt.title(f\"Histogram of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "\n",
    "    # 2️⃣ Boxplot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.boxplot(x=empdata[col])\n",
    "    plt.title(f\"Boxplot of {col}\")\n",
    "    plt.xlabel(col)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb50ce19",
   "metadata": {},
   "source": [
    "Most tenure and experience-related variables are right-skewed with notable outliers, indicating that the workforce is dominated by early-to-mid tenure employees, while long-tenured employees form a small minority, making these features important for attrition analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9841ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "cat_cols_no_attr = [col for col in cat_cols if col != 'Attrition']\n",
    "\n",
    "# Number of categorical columns\n",
    "n = len(cat_cols_no_attr)\n",
    "\n",
    "# Choose grid size (rows & cols)\n",
    "cols = 3 \n",
    "rows = math.ceil(n / 3)   # 3 columns per row \n",
    "\n",
    "plt.figure(figsize=(18, rows * 5))\n",
    "\n",
    "for i, col in enumerate(cat_cols_no_attr, 1):\n",
    "    plt.subplot(rows, cols, i)\n",
    "    sns.countplot(data=empdata, x=col)\n",
    "    plt.title(f\"Count Plot - {col}\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d72746",
   "metadata": {},
   "source": [
    "The workforce is concentrated in specific departments, job roles, and satisfaction levels, with limited variation in performance ratings and work–life balance, indicating structured organizational policies that may influence employee attrition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c0e1b4",
   "metadata": {},
   "source": [
    "**Bivariate Analysis** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce7196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Vs Attrition\n",
    "# Number of numerical columns\n",
    "n = len(num_cols)\n",
    "\n",
    "# Grid layout → 3 plots per row (you can change)\n",
    "rows = math.ceil(n / 3)\n",
    "cols = 3\n",
    "\n",
    "plt.figure(figsize=(18, rows * 5))\n",
    "\n",
    "for i, num in enumerate(num_cols, 1):\n",
    "    plt.subplot(rows, cols, i)\n",
    "    sns.boxplot(data=empdata, x=\"Attrition\", y=num)\n",
    "    plt.title(f\"{num} vs Attrition\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd891c36",
   "metadata": {},
   "source": [
    "Employees with lower income, lesser experience, shorter tenure, and longer commuting distances show higher attrition, while compensation rates alone exhibit limited discriminatory power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758a1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categrical Vs Attrition\n",
    "# Remove Attrition from categorical columns\n",
    "cat_cols_no_attr = [col for col in cat_cols if col != \"Attrition\"]\n",
    "\n",
    "# Number of categorical columns\n",
    "n = len(cat_cols_no_attr)\n",
    "\n",
    "# Grid layout → 3 plots per row (you can change)\n",
    "rows = math.ceil(n / 3)\n",
    "cols = 3\n",
    "\n",
    "plt.figure(figsize=(20, rows * 5))\n",
    "\n",
    "for i, col in enumerate(cat_cols_no_attr, 1):\n",
    "    plt.subplot(rows, cols, i)\n",
    "    sns.countplot(data=empdata, x=col, hue=\"Attrition\")\n",
    "    plt.title(f\"{col} vs Attrition\")\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccb1c64",
   "metadata": {},
   "source": [
    "Higher attrition is observed among employees with frequent travel, overtime work, lower job involvement and satisfaction, lower job levels, and limited stock options, highlighting work conditions and career growth as key drivers of attrition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53482489",
   "metadata": {},
   "source": [
    "**Correlation** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfb02bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation\n",
    "corr = empdata[num_cols].corr()\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    annot=True,\n",
    "    cmap='coolwarm',\n",
    "    linewidths=0.5,\n",
    "    fmt=\".2f\",\n",
    "    square=True\n",
    ")\n",
    "plt.title(\"Correlation Heatmap of Selected Features\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e20d3c9",
   "metadata": {},
   "source": [
    "Tenure and experience-related features exhibit strong positive intercorrelations indicating multicollinearity, while compensation rates and distance-related variables show weak linear relationships with other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a2d78f",
   "metadata": {},
   "source": [
    "**Chi- Square Contingency** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7040de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Copy dataset (safe practice)\n",
    "df = empdata.copy()\n",
    "\n",
    "# Select categorical columns\n",
    "cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Remove target column\n",
    "cat_cols.remove('Attrition')\n",
    "\n",
    "chi_results = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    # Create contingency table\n",
    "    contingency_table = pd.crosstab(df[col], df['Attrition'])\n",
    "\n",
    "    # Perform Chi-Square test\n",
    "    chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    chi_results.append({\n",
    "        'Feature': col,\n",
    "        'Chi2_Statistic': round(chi2, 3),\n",
    "        'p_value': round(p_value, 5),\n",
    "        'Significant (p<0.05)': 'Yes' if p_value < 0.05 else 'No'\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "chi_square_df = pd.DataFrame(chi_results)\n",
    "\n",
    "# Sort by p-value\n",
    "chi_square_df = chi_square_df.sort_values(by='p_value').reset_index(drop=True)\n",
    "\n",
    "chi_square_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31437fdb",
   "metadata": {},
   "source": [
    "Chi-square analysis shows that job-related factors such as OverTime, JobRole, and BusinessTravel are significantly associated with attrition, while Gender has no statistically significant impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41b0aea",
   "metadata": {},
   "source": [
    "**Annova**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e310618",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Detect target column (works if it's 'Attrition' or an encoded name like 'Attrition_Yes')\n",
    "if 'Attrition' in empdata.columns:\n",
    "    target_col = 'Attrition'\n",
    "else:\n",
    "    target_candidates = [c for c in empdata.columns if 'Attrition' in c]\n",
    "    if len(target_candidates) == 0:\n",
    "        raise KeyError(\"No column containing 'Attrition' found in empdata\")\n",
    "    target_col = target_candidates[0]\n",
    "\n",
    "# Numeric columns (exclude target if numeric)\n",
    "num_cols = empdata.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if target_col in num_cols:\n",
    "    num_cols = [c for c in num_cols if c != target_col]\n",
    "\n",
    "anova_results = []\n",
    "\n",
    "# Use the unique values of the target as group labels (keeps whatever form you have: 'Yes'/'No' or 0/1)\n",
    "group_labels = empdata[target_col].dropna().unique().tolist()\n",
    "\n",
    "for col in num_cols:\n",
    "    # build groups for this feature\n",
    "    groups = []\n",
    "    for g in group_labels:\n",
    "        vals = empdata.loc[empdata[target_col] == g, col].dropna().values\n",
    "        if len(vals) > 1:\n",
    "            groups.append(vals)\n",
    "\n",
    "    # need at least two groups with >1 sample to run ANOVA\n",
    "    if len(groups) < 2:\n",
    "        continue\n",
    "\n",
    "    # one-way ANOVA\n",
    "    f_stat, p_val = f_oneway(*groups)\n",
    "\n",
    "    # group means (safe retrieval)\n",
    "    means = {str(g): empdata.loc[empdata[target_col] == g, col].mean() for g in group_labels}\n",
    "\n",
    "    anova_results.append({\n",
    "        'Feature': col,\n",
    "        'F_statistic': float(f_stat),\n",
    "        'p_value': float(p_val),\n",
    "        **{f'Mean_{str(g)}': float(means.get(str(g), np.nan)) for g in group_labels}\n",
    "    })\n",
    "\n",
    "anova_df = pd.DataFrame(anova_results)\n",
    "\n",
    "# sort by p-value (smallest p first)\n",
    "anova_df = anova_df.sort_values('p_value').reset_index(drop=True)\n",
    "\n",
    "# show columns and top results\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(f\"Target column used for grouping: {target_col}\")\n",
    "anova_df.head(50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9550cb2f",
   "metadata": {},
   "source": [
    "ANOVA results indicate that experience, tenure, income, job level, and satisfaction-related variables significantly influence attrition, while compensation rates, performance rating, and education show no meaningful impact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a802fda",
   "metadata": {},
   "source": [
    "**Selected Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356dd01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_categorical_features = [\n",
    "    'BusinessTravel', 'Department', 'EducationField',\n",
    "    'EnvironmentSatisfaction', 'JobInvolvement',\n",
    "    'JobRole', 'JobSatisfaction', 'MaritalStatus',\n",
    "    'OverTime', 'StockOptionLevel', 'WorkLifeBalance', 'JobLevel'\n",
    "]\n",
    "\n",
    "s_numerical_features = [\n",
    "    'Age', 'DailyRate', 'DistanceFromHome', 'MonthlyIncome',\n",
    "    'TotalWorkingYears', 'YearsAtCompany', 'YearsInCurrentRole',\n",
    "    'YearsWithCurrManager', 'YearsSinceLastPromotion',\n",
    "    'TrainingTimesLastYear'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5ce9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multicollinearity Analysis of Numerical Features\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "sns.heatmap(\n",
    "    empdata[s_numerical_features].corr(),\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    ")\n",
    "\n",
    "plt.title(\"Correlation Heatmap of Numerical Features\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea1c793",
   "metadata": {},
   "source": [
    "**Final Selected Feature**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fe59a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final selected features (updated)\n",
    "\n",
    "f_numerical_features = [\n",
    "    'Age',\n",
    "    'MonthlyIncome',\n",
    "    'TotalWorkingYears',\n",
    "    'YearsAtCompany',\n",
    "    'YearsInCurrentRole',\n",
    "    'YearsWithCurrManager'\n",
    "]\n",
    "\n",
    "f_categorical_features = [\n",
    "    'OverTime',\n",
    "    'JobRole',\n",
    "    'JobLevel',\n",
    "    'EnvironmentSatisfaction',\n",
    "    'WorkLifeBalance'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbed6b4f",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3794e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Encoding (Label + One-Hot)\n",
    "\n",
    "binary_encoded_cols = []\n",
    "\n",
    "for col in f_categorical_features:\n",
    "\n",
    "    # Binary categorical → Label Encoding (0 / 1)\n",
    "    if empdata[col].nunique() == 2:\n",
    "        empdata[col] = pd.factorize(empdata[col])[0]\n",
    "        binary_encoded_cols.append(col)\n",
    "\n",
    "    # Multi-class categorical → One-Hot Encoding\n",
    "    elif 2 < empdata[col].nunique() < 10:\n",
    "        dummies = pd.get_dummies(empdata[col], drop_first=False, prefix=col,dtype=int)\n",
    "        empdata = pd.concat([empdata.drop(col, axis=1), dummies], axis=1)\n",
    "\n",
    "# One-hot encoded columns\n",
    "encoded_cols = [\n",
    "    c for c in empdata.columns\n",
    "    if any(c.startswith(f + \"_\") for f in f_categorical_features)\n",
    "]\n",
    "\n",
    "# Final dataset (numerical + binary categorical + one-hot + target)\n",
    "empdata = empdata[\n",
    "    f_numerical_features + binary_encoded_cols + encoded_cols + ['Attrition']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36336e17",
   "metadata": {},
   "source": [
    "**Outlier Treatment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaffc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier treatent\n",
    "\n",
    "df_out = empdata.copy()\n",
    "\n",
    "mask = pd.Series(True, index=df_out.index)\n",
    "\n",
    "for col in f_numerical_features:\n",
    "    features = df_out[col].quantile(0.25)\n",
    "    Q3 = df_out[col].quantile(0.75)\n",
    "    IQR = Q3 - features\n",
    "\n",
    "    mask &= (\n",
    "        (df_out[col] >= features - 1.5 * IQR) &\n",
    "        (df_out[col] <= Q3 + 1.5 * IQR)\n",
    "    )\n",
    "\n",
    "df_out = df_out[mask].reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b69e3c",
   "metadata": {},
   "source": [
    "**SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d3d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "\n",
    "# One-hot encoding\n",
    "df_encoded = pd.get_dummies(df_out, drop_first=True)\n",
    "\n",
    "# Target column AFTER encoding\n",
    "target_col = \"Attrition_Yes\"\n",
    "x = df_encoded.drop(columns=[target_col])\n",
    "y = df_encoded[target_col]\n",
    "\n",
    "# Apply SMOTE\n",
    "sm = SMOTE(random_state=0)\n",
    "x_sm, y_sm = sm.fit_resample(X, y)\n",
    "\n",
    "print(\"Before SMOTE:\\n\", y.value_counts())\n",
    "print(\"\\nAfter SMOTE:\\n\", y_sm.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e922ef9",
   "metadata": {},
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b7cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_sm, y_sm,\n",
    "    test_size=0.20,\n",
    "    random_state=42,\n",
    "    stratify=y_sm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38317ac",
   "metadata": {},
   "source": [
    "**Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4554dcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler()\n",
    "\n",
    "x_train_scaled = pd.DataFrame(\n",
    "    std.fit_transform(x_train),\n",
    "    columns=x_train.columns,\n",
    "    index=x_train.index\n",
    ")\n",
    "\n",
    "x_test_scaled = pd.DataFrame(\n",
    "    std.transform(x_test),\n",
    "    columns=x_train.columns,\n",
    "    index=x_test.index\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4d7638",
   "metadata": {},
   "source": [
    "**Score Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574ee8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification summary (focused metrics)\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    f1_score, recall_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(columns=['model', 'recall_macro'])\n",
    "\n",
    "\n",
    "def classification_summary(model, y_test, pred, pred_prob):\n",
    "    print(\"\\n--- model evaluation ---\")\n",
    "    print(f\"model: {model.__class__.__name__}\")\n",
    "\n",
    "    # key metrics\n",
    "    print(\"recall (yes):\", round(recall_score(y_test, pred), 3))\n",
    "    print(\"f1 score (macro):\", round(f1_score(y_test, pred, average='macro'), 3))\n",
    "    print(\"auc-roc:\", round(roc_auc_score(y_test, pred_prob[:, 1]), 3))\n",
    "\n",
    "    print(\"\\nconfusion matrix:\")\n",
    "    print(confusion_matrix(y_test, pred))\n",
    "\n",
    "    print(\"\\nclassification report:\")\n",
    "    print(classification_report(y_test, pred))\n",
    "\n",
    "    results_df.loc[len(results_df)] = [\n",
    "        model.__class__.__name__,\n",
    "        f1_score(y_test, pred, average='macro')\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57959e5f",
   "metadata": {},
   "source": [
    "**Multiple Models & Comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2915978b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train_scaled, y_train)\n",
    "\n",
    "pred = model.predict(x_test_scaled)\n",
    "pred_prob = model.predict_proba(x_test_scaled)\n",
    "\n",
    "classification_summary(model, y_test, pred, pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9536d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "pred_prob = model.predict_proba(x_test)\n",
    "\n",
    "# Evaluation\n",
    "classification_summary(model, y_test, pred, pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9666bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "pred_prob = model.predict_proba(x_test)\n",
    "\n",
    "# Evaluation\n",
    "classification_summary(model, y_test, pred, pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5ed66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "pred_prob = model.predict_proba(x_test)\n",
    "\n",
    "# Evaluation\n",
    "classification_summary(model, y_test, pred, pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a5ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"logloss\",\n",
    "    random_state=42,\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "pred_prob = model.predict_proba(x_test)\n",
    "\n",
    "# Evaluation\n",
    "classification_summary(model, y_test, pred, pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303060e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.sort_values(by='recall_macro', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14235ae3",
   "metadata": {},
   "source": [
    "**Save to Pickle File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65093ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4775d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best trained model as a pickle file\n",
    "\n",
    "import pickle\n",
    "\n",
    "file_path = (r\"G:\\DS_Projects\\.venv\\Employee_Attrition\\best_model.pkl\")\n",
    "\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(best_model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
